<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Seed1.6-Embedding"> <!-- TODO: add some description, visible outside -->
  <meta name="keywords" content="Seed1.6-Embedding, Embedding, MTEB, BRIGHT, ByteDance Seed"> <!-- TODO: add some keywords for search engine -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Seed1.6-Embedding</title>
  <meta name="google-site-verification" content="7653B2lNOxQfqnLK-cp_7FFy9QsWIOJy4g7oZGWYLRo" />


  <script async src="./static/js/tech-mml-chtml.js"></script>

  <!-- Replace Prism.js with highlight.js for better markdown-style highlighting -->
  <link rel="stylesheet" href="./static/css/github.min.css">
  <script src="./static/js/highlight.min.js"></script>
  <script src="./static/js/languages/python.min.js"></script>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FHJFH93Y3V"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FHJFH93Y3V');
  </script>

  <!-- Remove unused fonts, keep only necessary ones -->
  <link href="./static/css/fonts.css"
        rel="stylesheet">

  <!-- Remove unused CSS files -->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome_6_7_2.all.css">
  <link rel="stylesheet"
        href="./static/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <!-- Remove unused JS files -->
  <script src="./static/js/jquery.js"></script>
  <script defer src="./static/js/fontawesome_6_7_2.all.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* 统一使用flex布局控制间距，同时保持原有的宽度限制 */
    .main-content {
      display: flex;
      flex-direction: column;
      gap: 4rem;  /* 统一设置所有主要部分之间的间距 */
      max-width: 100%;  /* 确保不会超出父容器 */
    }

    .container.is-max-desktop {
      max-width: 960px;
      width: 100%;
      margin: 0 auto;
      padding: 0 20px;  /* 统一设置容器的内边距 */
    }

    /* 更新图片容器样式 */
    .has-text-centered {
      padding: 0 !important;  /* 移除额外的内边距 */
      width: 100%;           /* 确保容器占满宽度 */
    }

    .has-text-centered img {
      width: 100%;          /* 图片填充整个容器宽度 */
      max-width: 100%;      /* 确保图片不会溢出 */
      border-radius: 15px;
      display: block;       /* 移除图片下方的空隙 */
    }

    /* 移除之前的margin设置 */
    .hero-body img {
      margin-bottom: 0 !important;
    }

    .section-content {
      margin-bottom: 0;
    }

    /* 让 footer 高度自适应内容 */
    .footer {
      padding-top: max(0.3rem, min(0.5rem, 0.5vh));    /* 稍微增加一点内边距 */
      padding-bottom: max(0.3rem, min(0.5rem, 0.5vh));
      height: fit-content;
      display: flex;
      align-items: center;
      min-height: 0;  /* 覆盖 Bulma 的默认最小高度 */
    }

    .footer .content {
      margin: 0;
      padding: 0;  /* 确保没有额外的内边距 */
      line-height: 1.2;  /* 减小行高 */
    }

    .footer p {
      margin: 0;  /* 移除段落的默认边距 */
    }

    /* 语言切换按钮容器 */
    .language-switcher {
      position: fixed;
      top: 20px;
      right: 20px;
      z-index: 1000;
    }

    .switch-container {
      width: 80px;
      height: 2.5em;
      background-color: #fff;
      transition: background-color .3s ease-in-out;
      display: grid;      /* 使用grid布局 */
      place-items: center; /* 完美居中 */
    }

    .switch-label {
      font-size: 14px;
      font-weight: 500;    /* 降低字重，统一中英文显示效果 */
      color: #485fc7;
      cursor: pointer;
      user-select: none;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;  /* 使用系统字体栈 */
    }

    .switch-container:hover {
      background-color: #f9f9f9;
    }

    /* 响应式调整 */
    @media (max-width: 768px) {
      .language-switcher {
        top: 12px;
        right: 12px;
      }
    }

    /* 更新logo和文本容器的样式 */
    .hero .container {
      max-width: 800px;  /* 限制最大宽度 */
      margin: 0 auto;
      padding: 0 20px;   /* 添加两侧内边距 */
    }

    /* 更新响应式调整 */
    @media screen and (max-width: 768px) {
      .container.is-max-desktop {
        padding: 0 15px;    /* 移动端稍微减小内边距 */
      }
      
      .has-text-centered {
        margin: 0;          /* 移除之前的负margin */
        width: 100%;        /* 设置为100%宽度 */
        padding: 0 !important;  /* 移除内边距 */
      }
      
      .has-text-centered img {
        width: 100%;        /* 修改：移动端图片宽度设为100% */
        margin: 0 auto;     /* 水平居中 */
        border-radius: 10px;  /* 移动端稍微减小圆角 */
      }
    }

    /* 调整标题、作者和按钮之间的间距 */
    .publication-title {
      margin-bottom: 1.5rem !important;  /* 标题到作者的间距 */
    }

    .publication-authors {
      margin-bottom: 2rem !important;  /* 作者到按钮的间距 */
    }

    /* 增加按钮和图片之间的间距 */
    .publication-links {
      margin-bottom: 3rem !important;  /* 按钮到图片的间距 */
    }

    /* 小文本样式 */
    .model-id {
      font-size: 12px;
      color: #666;
      margin-top: 8px;
      opacity: 0.8;
    }

    /* 更新 hero 容器样式以匹配其他内容区域 */
    .hero .container.is-max-desktop {
      max-width: 960px;  /* 与其他 container.is-max-desktop 保持一致 */
      width: 100%;
      margin: 0 auto;
      padding: 0 20px;
    }

    /* 更新图片容器样式 */
    .hero .column.has-text-centered {
      width: 100%;
      max-width: 100%;
      padding: 0 1.5rem;  /* 添加与文字容器相同的内边距 */
    }

    /* 更新所有主要内容列的宽度 */
    .column.is-four-fifths,
    .hero .column.has-text-centered {
      width: 100%;
      max-width: 800px;  /* 限制最大宽度 */
      margin: 0 auto;
      padding: 0 20px;   /* 添加两侧内边距 */
    }

    @media screen and (max-width: 768px) {
      .container.is-max-desktop,
      .hero .container.is-max-desktop {
        padding: 0 15px;
      }
      
      .hero .column.has-text-centered,
      .column.is-four-fifths {  /* 确保所有主要内容列使用相同的宽度 */
        width: 100%;
        padding: 0 15px;  /* 移动端时使用相同的内边距 */
      }
      
      .has-text-centered img {
        width: 100%;
        margin: 0 auto;
        border-radius: 10px;
      }
    }
  </style>

</head>

<body>

<!-- 简化语言切换按钮的 HTML -->
<div class="language-switcher">
  <button class="switch-container button is-normal is-rounded" onclick="switchLanguage('zh')">
    <span class="switch-label lang-en">中文</span>
  </button>
  <button class="switch-container button is-normal is-rounded" style="display: none;" onclick="switchLanguage('en')">
    <span class="switch-label lang-zh">English</span>
  </button>
</div>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>

<!-- 在logo后面开始，到Usage结束的内容都包在这个div里 -->
<div class="main-content">
  <div class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              Seed1.6-Embedding
            </h1>

            <div class="is-size-5 publication-authors">
                <span class="author-block lang-en">ByteDance Seed</span>
                <span class="author-block lang-zh" style="display: none;">字节跳动 Seed</span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-embedding-vision"
                     class="external-link button is-normal is-rounded" target="_blank">
                    <span class="icon">
                        <i class="fa-solid fa-arrow-up-right-from-square"></i>
                    </span>
                    <span class="lang-en">API on Volcengine</span>
                    <span class="lang-zh" style="display: none;">火山引擎API</span>
                  </a>
                  <div class="model-id">
                    <span class="lang-en">Model ID: doubao-embedding-vision-250615</span>
                    <span class="lang-zh" style="display: none;">模型ID：doubao-embedding-vision-250615</span>
                  </div>
                </span>
              </div>
            </div>
            <div class="has-text-centered">
              <img src="./static/images/model.png" alt="Seed1.6-Embedding model" style="border-radius: 15px;">
              <!-- <img src="./static/images/model_info.png" alt="Seed1.6-Embedding Logo" style="border-radius: 15px;"> -->
            </div>


          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="section-content">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">
            <span class="lang-en">Introduction</span>
            <span class="lang-zh" style="display: none;">介绍</span>
          </h2>
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                We launched Seed-1.6-Embedding, a powerful embedding model built on Seed1.6-flash. It stands out with the following key features:
              </p>
              <ul>
                <li>
                  <strong>Multimodal Hybrid Retrieval</strong>: Supports hybrid retrieval among text, image, and video modalities.
                </li>
                <li>
                  <strong>SOTA Performance</strong>: Achieved a new SOTA score on the CMTEB leaderboard for plain text tasks and MMEB-V2 leaderboard for multimodal tasks. 
                </li>
                <li>
                  <strong>Flexibility</strong>: Supports multiple embedding dimensions -[2048, 1024] with minimal performance degradation at lower dimensions.
                </li>
              </ul>

            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                我们推出了 Seed-1.6-Embedding，这是一个基于Seed1.6-flash构建的强大嵌入模型。它具有以下关键特性: 
              </p>
              <ul>
                <li>
                  <strong>多模态混合检索</strong>: 支持文本、图像和视频模态之间的混合检索。
                </li>
                <li>
                  <strong>SOTA性能</strong>: 在纯文本任务的CMTEB排行榜和多模态任务的MMEB-V2排行榜上均取得了新的SOTA分数。 
                </li>
                <li>
                  <strong>灵活性</strong>: 支持多种嵌入维度 —[2048, 1024] 在较低维度下仍保持较好效果。
                </li>
              </ul>


            </div>
          </div>
          <h3 class="title is-5">
            <span class="lang-en">Model Architecture</span>
            <span class="lang-zh" style="display: none;">模型结构</span>
          </h3>
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                The model architecture is based on seed1.6-flash, which fully preserves and enhances the model's multimodal understanding capabilities for text, images, videos, and mixed modalities. It is based on a dual-tower structure, with the embedding vector extracted corresponding to the last hidden layer vector of the [EOS] token.
              </p>
            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                基于seed1.6-flash，充分保留和增强模型对于文本、图片、视频以及混合模态的多模态理解能力，基于双塔结构，embedding向量提取与[EOS]token 对应的最后一层隐向量。
              </p>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>

  <div class="section-content">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">
            <span class="lang-en">Training Method</span>
            <span class="lang-zh" style="display: none;">训练方法</span>
          </h2>
          
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                During the construction of the embedding model, we employed a phased training strategy to progressively improve model performance and successfully developed the powerful doubao-embedding-vision model. The entire training process consists of three core stages.
              </p>
            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                在 embedding 模型的构建过程中，我们使用了分阶段训练策略，逐步提升模型性能，最终成功塑造出功能强大的 doubao-embedding-vision 模型。整个训练流程由三个核心阶段组成。
              </p>
            </div>
          </div>
          <h3 class="title is-5">
            <span>Stage1: Text Continue Training</span>
          </h3>
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                <strong>Training Objectives</strong>: The objective of this stage is to endow the model with basic embedding capabilities, transforming the VLM model into one that possesses embedding capabilities.
              </p>
            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                <strong>训练目标</strong>: 这一阶段的目标是赋予模型基础的 embedding 能力，将vlm模型转变为具备embedding模型。
              </p>
            </div>
          </div>
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                <strong>Training Strategy</strong>: We utilized large-scale pure text data as training data, which includes multi-domain public data collected from the internet and some synthetic data. For public data, we designed sophisticated data cleaning algorithms and filtering rules to remove noise, duplicate content, and irrelevant information, ensuring high-quality data. Synthetic data, on the other hand, is expanded based on specific seed data using large language models, enabling the synthetic data to cover various domain knowledge and topics. During training, each sample is a text pair, and the InfoNCE loss function is used for contrastive learning.
              </p>
            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                <strong>训练策略</strong>: 我们使用了大规模纯文本数据作为训练数据，涵盖了从互联网采集的多领域公开数据以及部分合成数据。对于公开数据，我们设计了精巧的数据清洗算法和过滤规则，去除其中的噪声、重复内容以及无关信息，保证数据的高质量。而合成数据则是基于特定的种子数据，借助大语言模型进行扩展，使得合成的数据能够覆盖各类不同的领域知识和话题。训练过程中，每条样本是一个文本对，并采用 infoNce 损失函数进行对比学习。
              </p>
            </div>
          </div>

          <!-- stage2 -->

          <h3 class="title is-5">
            <span>Stage 2: Multimodal Continue Training</span>
          </h3>
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                <strong>Training Objectives</strong>: Building on the previous stage, the objective is to add multimodal alignment capabilities for text, images, and videos.
              </p>
            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                <strong>训练目标</strong>: 在上一阶段的基础上，增加文、图、视频的多模态对齐能力。
              </p>
            </div>
          </div>
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                <strong>Training Strategy</strong>: We collected a large-scale dataset of tens of millions of image-text pairs and video-text pairs for training. A portion of this raw data was sourced from the internet. To ensure data quality, we first conducted rigorous cleaning and filtering of the images, removing those that were blurry, damaged, or low-resolution. Additionally, to construct high-quality image-text pairs, we designed a data production process to obtain accurate and detailed captions from the raw images, ensuring precise semantic alignment between images and text. During training, we again employed the InfoNCE loss function, optimizing the distance between image-text pairs in the vector space to continuously enhance the model's understanding of multimodal data.
              </p>
            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                <strong>训练策略</strong>: 我们收集了千万级规模的图文对、视频-文对数据用于训练。这些原始数据一部分采集自互联网，为确保数据质量，首先对其中的图片进行严格的清洗和过滤，剔除模糊、损坏、低分辨率等不合格的图片。同时，为了构建高质量的图文样本对，我们设计了一套数据生产流程，从原始图片中获取准确、详细的 caption，使图文语义实现精准匹配。在训练过程中，同样采用 infoNce 损失函数，通过优化图文对在向量空间中的距离，不断强化模型对多模态数据的理解能力。
              </p>
            </div>
          </div>

          <!-- stage 3 -->

          <h3 class="title is-5">
            <span>Stage 3: Fine-Tuning</span>
          </h3>
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                <strong>Training Objectives</strong>: The objective of this stage is to comprehensively improve the model's ability to handle various niche scenarios and complex tasks by introducing data of different forms, modalities, and task types. This will enable the model to better meet the practical application requirements of information retrieval and content classification.
              </p>
            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                <strong>训练目标</strong>: 这一阶段的目标是通过引入不同形式、模态以及任务类型的数据，全面提升模型在各类细分场景和复杂任务下的处理能力，使其能够更好地适配信息检索、内容分类等实际应用需求。
              </p>
            </div>
          </div>
          <div class="content has-text-justified">
            <!-- 英文版介绍 -->
            <div class="lang-en">
              <p>
                <strong>Training Strategy</strong>: We systematically constructed a high-quality fine-tuning dataset by focusing on three key dimensions: task type, input data modality, and task scenario. On one hand, we referenced the task types and data structures of publicly available benchmark datasets. On the other hand, we closely integrated the actual business needs and extensive experience of ByteEngine to create dozens of datasets for different tasks. For each dataset, we designed specific instructions tailored to its characteristics and scenario requirements, guiding the model to learn the logic of handling specific tasks and to develop a certain level of generalization ability. For scenarios and tasks with limited training data, we applied data augmentation and synthesis techniques to expand the data scale. For more challenging tasks with poor training outcomes, we targeted the mining of negative samples at different difficulty levels to improve the model's performance in complex tasks. Finally, we conducted mixed training on all datasets, iterating through multiple rounds of optimization. This process enabled the Doubao-Embedding-Vision model to demonstrate strong generalization capabilities and excellent performance across various niche scenarios.
              </p>
            </div>
            <!-- 中文版介绍 -->
            <div class="lang-zh" style="display: none;">
              <p>
                <strong>训练策略</strong>: 我们从任务类型、输入数据模态、任务场景三个关键维度出发，系统性地构建高质量的微调数据集。一方面参考公开评测集的任务类型和数据结构，另一方面紧密结合火山引擎的实际业务需求与丰富经验，构建了数十个不同任务的数据集。针对每个数据集的特点和场景需求，我们设计了专属的指令，以引导模型学习特定任务的处理逻辑，并具备一定的泛化能力。对于部分训练数据匮乏的场景和任务，我们运用数据增强和合成技术，扩充数据规模；对于难度较高，训练效果不佳的任务，定向挖掘不同难度层次的负样本，以此提升模型在复杂任务下的表现。最后，将所有数据集进行混合训练，经过多轮迭代优化，使得 doubao-embedding-vision 模型在不同的细分场景下都展现出强大的泛化能力和优异的性能表现。
              </p>
            </div>
          </div>

    

        </div>
      </div>
    </div>
  </div>

  

  <div class="section-content">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">
            <span class="lang-en">Performance</span>
            <span class="lang-zh" style="display: none;">效果</span>
          </h2>
          
          <div class="performance-section">
            <div style="margin-bottom: 2rem;">
              <div class="content has-text-justified">
                <!-- 英文版介绍 -->
                <div class="lang-en">
                  <p>
                    In the authoritative leaderboards that best reflect the model's generalization ability, Seed1.6-Embedding has demonstrated significant advantages:
                  </p>
                </div>
                <!-- 中文版介绍 -->
                <div class="lang-zh" style="display: none;">
                  <p>
                    在最能体现模型泛化能力的权威榜单中，Seed1.6-Embedding 均展现出显著优势:
                  </p>
                </div>
              </div>
                <h3 class="title is-5">C-MTEB (Chinese)</h3>
                <div class="table-container">
                  <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth performance-table">
                    <thead>
                      <tr>
                        <th class="model-column has-text-centered">Model</th>
                        <th>AVG</th>
                        <th>Classification</th>
                        <th>Clustering</th>
                        <th>Pair Classification</th>
                        <th>Reranking</th>
                        <th>Retrieval</th>
                        <th>STS</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr class="highlight-row">
                        <td class="has-text-centered"><strong>Seed1.6-Embedding</strong></td>
                        <td><strong>75.66</strong></td>
                        <td>78.20</td>
                        <td>73.11</td>
                        <td>88.71</td>
                        <td>71.65</td>
                        <td><strong>79.69</strong></td>
                        <td><strong>68.93</strong></td>
                      </tr>
                      <tr class="highlight-row">
                        <td class="has-text-centered">Seed1.5-Embedding</td>
                        <td>74.87</td>
                        <td>79.37</td>
                        <td>71.11</td>
                        <td>89.57</td>
                        <td>70.14</td>
                        <td>79.33</td>
                        <td>66.56</td>
                      </tr>
                      <tr>
                        <td class="has-text-centered">Conan-embedding-v2</td>
                        <td>74.24</td>
                        <td>76.47</td>
                        <td>68.84</td>
                        <td>92.44</td>
                        <td>74.41</td>
                        <td>78.31</td>
                        <td>65.48</td>
                      </tr>
                      <tr>
                        <td class="has-text-centered">Qwen3-Embedding-8B</td>
                        <td>73.84</td>
                        <td>76.97</td>
                        <td>80.08</td>
                        <td>84.23</td>
                        <td>66.99</td>
                        <td>78.21</td>
                        <td>63.53</td>
                      </tr>
                    </tbody>
                  </table>
                </div>
                <div class="content has-text-justified">
                  <!-- 英文版介绍 -->
                  <div class="lang-en">
                    <p>
                      <strong>Pure Text Tasks</strong>: On the CMTEB Chinese Text Vector Evaluation leaderboard, our model has set a new SOTA with a high score of 75.62, continuing to lead in general tasks such as retrieval, classification, and semantic matching.
                    </p>
                  </div>
                  <!-- 中文版介绍 -->
                  <div class="lang-zh" style="display: none;">
                    <p>
                      <strong>纯文本任务</strong>: 在 CMTEB 中文文本向量评测榜单上，模型以75.62高分刷新榜单 SOTA，在检索、分类、语义匹配等通用任务表现持续领跑。
                    </p>
                  </div>
                </div>

            </div>
            <div style="margin-bottom: 2rem;">
                <h3 class="title is-5">MMEB-V2</h3>
                <div class="table-container">
                    <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth performance-table">
                        <thead>
                            <tr>
                                <th class="model-column has-text-centered">Model</th>
                                <th>Overall</th>
                                <th>Image-Overall</th>
                                <th>Video-Overall</th>
                                <th>Visdoc-Overall</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="highlight-row">
                                <td class="has-text-centered"><strong>Seed1.6-Embedding</strong></td>
                                <td><strong>71.57</strong></td>
                                <td><strong>77.78</strong></td>
                                <td><strong>55.34</strong></td>
                                <td><strong>74.41</strong></td>
                            </tr>
                            <tr class="highlight-row">
                                <td class="has-text-centered">VLM2Vec-V2.0-Qwen2VL-2B</td>
                                <td>58.39</td>
                                <td>64.85</td>
                                <td>34.85</td>
                                <td>66.34</td>
                            </tr>
                            <tr>
                                <td class="has-text-centered">gme-Qwen2-VL-2B-Instruct</td>
                                <td>54.37</td>
                                <td>51.89</td>
                                <td>33.86</td>
                                <td>73.47</td>
                            </tr>
                            <tr>
                                <td class="has-text-centered">VLM2Vec-V1-Qwen2VL-7B</td>
                                <td>52.33</td>
                                <td>65.49</td>
                                <td>34.01</td>
                                <td>46.32</td>
                            </tr>
                            <tr>
                                <td class="has-text-centered">LamRA-Ret-Qwen2.5VL-7b</td>
                                <td>47.76</td>
                                <td>52.43</td>
                                <td>33.68</td>
                                <td>51.32</td>
                            </tr>
                            <tr>
                                <td class="has-text-centered">VLM2Vec-V1-Qwen2VL-2B</td>
                                <td>47.14</td>
                                <td>59.74</td>
                                <td>28.97</td>
                                <td>41.85</td>
                            </tr>
                            <tr>
                                <td class="has-text-centered">colpali-v1.3</td>
                                <td>44.54</td>
                                <td>34.89</td>
                                <td>28.28</td>
                                <td>71.22</td>
                            </tr>
                            <tr>
                                <td class="has-text-centered">LamRA-Ret</td>
                                <td>40.47</td>
                                <td>54.08</td>
                                <td>35.24</td>
                                <td>23.97</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <div class="content has-text-justified">
                  <!-- 英文版介绍 -->
                  <div class="lang-en">
                    <p>
                      <strong>Multimodal Tasks</strong>: On the MMEB_v2 multimodal evaluation leaderboard, the model has topped the SOTA in both image and video tasks, achieving a significant lead. Specifically, on the MMEB_v2 Image leaderboard, the model scored an impressive 77.78, leading the second place by 5.6 points. In the newly added video modality, the model has also achieved a substantial lead on the MMEB_v2 Video leaderboard, outperforming the second place by 20.1 points.

                    </p>
                  </div>
                  <!-- 中文版介绍 -->
                  <div class="lang-zh" style="display: none;">
                    <p>
                      <strong>多模态任务</strong>: 在多模态评测榜单 MMEB_v2中，模型的图片、视频向量化任务双双登顶 SOTA，并实现断层领先。其中在 MMEB_v2 Image 榜单上，模型以77.78的高分领先第二名5.6分；模型新增的视频模态，在 MMEB_v2 video 榜单大幅领先第二名20.1分。
                    </p>
                  </div>
                </div>

            </div>


          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="section-content">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">
            <span class="lang-en">Usage</span>
            <span class="lang-zh" style="display: none;">使用方法</span>
          </h2>
          <div class="content has-text-left">
            <div class="code-container">
              <button class="copy-button" onclick="copyCode(this)">
                <span class="lang-en">Copy</span>
                <span class="lang-zh" style="display: none;">复制</span>
              </button>
              <!-- 英文版代码 -->
              <pre class="lang-en"><code class="language-python">from volcenginesdkarkruntime import Ark
client = Ark()

print("----- multimodal embeddings request -----")
resp = client.multimodal_embeddings.create(
    model="doubao-embedding-vision-250615",
    input=[
        {
            "type":"text",
            "text":"天很蓝，海很深"
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg"
            }
        }
    ]
)
print(resp)
                </code></pre>

              <!-- 中文版代码 -->
              <pre class="lang-zh" style="display: none;"><code class="language-python">from volcenginesdkarkruntime import Ark
client = Ark()

print("----- multimodal embeddings request -----")
resp = client.multimodal_embeddings.create(
    model="doubao-embedding-vision-250615",
    input=[
        {
            "type":"text",
            "text":"天很蓝，海很深"
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg"
            }
        }
    ]
)
print(resp)
                </code></pre>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

</div>
  




<footer class="footer">
  <div class="container is-max-desktop">
    <div class="content has-text-centered">
      <p class="lang-en">
        This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a>.
      </p>
      <p class="lang-zh" style="display: none;">
        本网站改编自 <a href="https://nerfies.github.io/">Nerfies</a>。
      </p>
    </div>
  </div>
</footer>

<!-- Initialize highlight.js -->
<script>
hljs.highlightAll();

// Copy code functionality
function copyCode(button) {
    const codeBlock = button.parentElement.querySelector(`.lang-${currentLang} code`);
    const text = codeBlock.textContent;
    
    navigator.clipboard.writeText(text).then(function() {
        // 更新按钮文本以提供反馈
        const originalText = button.textContent;
        if (currentLang === 'en') {
            button.textContent = 'Copied!';
        } else {
            button.textContent = '已复制!';
        }
        button.classList.add('copied');
        
        // 2秒后恢复原始文本
        setTimeout(function() {
            if (currentLang === 'en') {
                button.textContent = 'Copy';
            } else {
                button.textContent = '复制';
            }
            button.classList.remove('copied');
        }, 2000);
    }).catch(function(err) {
        console.error('Failed to copy: ', err);
        if (currentLang === 'en') {
            button.textContent = 'Copy failed';
        } else {
            button.textContent = '复制失败';
        }
        
        setTimeout(function() {
            if (currentLang === 'en') {
                button.textContent = 'Copy';
            } else {
                button.textContent = '复制';
            }
        }, 2000);
    });
}

// Language switching functionality
let currentLang = 'en';
let originalContent = null;

// 页面加载完成后保存原始内容
document.addEventListener('DOMContentLoaded', function() {
  const mainContent = document.querySelector('.main-content');
  originalContent = mainContent.innerHTML;
});

function switchLanguage(lang) {
  const mainContent = document.querySelector('.main-content');
  const enButton = document.querySelector('.switch-container:has(.lang-en)');
  const zhButton = document.querySelector('.switch-container:has(.lang-zh)');
  
  // 添加淡出效果
  mainContent.style.opacity = '0';
  mainContent.style.transition = 'opacity 0.3s ease';
  
  setTimeout(() => {
    if (lang === 'zh') {
      // 切换到中文
      currentLang = 'zh';
      
      // 隐藏英文内容和按钮，显示中文内容和按钮
      document.querySelectorAll('.lang-en').forEach(el => el.style.display = 'none');
      document.querySelectorAll('.lang-zh').forEach(el => el.style.display = 'block');
      
      // 切换按钮显示
      enButton.style.display = 'none';
      zhButton.style.display = 'grid';  // 使用grid以保持居中效果
      
      // 更新按钮文字
      zhButton.querySelector('.switch-label').textContent = 'English';
      enButton.querySelector('.switch-label').textContent = '中文';
      
    } else {
      // 切换到英文
      currentLang = 'en';
      
      // 隐藏中文内容和按钮，显示英文内容和按钮
      document.querySelectorAll('.lang-zh').forEach(el => el.style.display = 'none');
      document.querySelectorAll('.lang-en').forEach(el => el.style.display = 'block');
      
      // 切换按钮显示
      zhButton.style.display = 'none';
      enButton.style.display = 'grid';  // 使用grid以保持居中效果
      
      // 更新按钮文字
      enButton.querySelector('.switch-label').textContent = '中文';
      zhButton.querySelector('.switch-label').textContent = 'English';
    }
    
    // 淡入新内容
    setTimeout(() => {
      mainContent.style.opacity = '1';
    }, 50);
    
  }, 300); // 等待淡出动画完成
}

// 添加主内容过渡样式
const style = document.createElement('style');
style.textContent = `
  .main-content {
    transition: opacity 0.3s ease;
  }
`;
document.head.appendChild(style);
</script>







</body>
</html>
